{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code modified from Matthew A. Russell's book \"Mining the Social Web: Data Mining Facebook, Twitter, LinkedIn, Google+, GitHub, and More\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "%qtconsole --colors=Linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nhashtag_search = \"#JeSuisParis\"\\ncount = 300\\n\\nsearch_res = twitter_api.search.tweets(q=hashtag_search,count = count)\\nstatuses = search_res[\\'statuses\\']\\n#\\t\\tIterate through 5 more batches of results by following the cursor\\n\\nfor _ in range(5):\\n\\tprint(\"Length of statuses\",len(statuses))\\n\\ttry: \\n\\t\\tnext_res = search_res[\\'search_metadata\\'][\\'next_res\\']\\n\\texcept KeyError as e: #\\t\\tNo more results when results don\\'t exist\\n\\t\\tbreak\\n\\t#\\t\\tCreate a dict from next_res\\n\\tkwargs = dict([kv.split(\\'=\\') for kv in next_res[1:].split(\\'&\\')])\\n\\tsearch_res = twitter_api.search.tweets(**kwargs)\\n\\tstatuses+=search_res[\\'statuses\\']\\n\\n#print(json.dumps(statuses[0],indent =1))\\n\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import twitter\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Set up API to my personal twitter account via Twitter's Python module\n",
    "\n",
    "CONSUMER_KEY = \"SixboXZyf3ODcR0K2vdAjj7nh\"\n",
    "CONSUMER_SECRET = \"RoOFdhL7OO2sDMIYwbAh1IJnm2r0qA3n9iQFTj4owpUVutvWOd\"\n",
    "OAUTH_TOKEN = \"36209712-WnGG44AXJ9xWHP7jtmTWPyInxrETh20uY7OqJnsvE\"\n",
    "OAUTH_TOKEN_SECRET = \"cmKF3sY3fuvfzialocuXcPbw0DDlx84L7gBKQnGrE0t6r\"\n",
    "auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET, CONSUMER_KEY, CONSUMER_SECRET)\n",
    "twitter_api = twitter.Twitter(auth = auth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function accepts my api, search query, and max number of results and returns most recent dict of twitter data\n",
    "def twitter_search(twitter_api, q, max_results=1000):\n",
    "    search_results = twitter_api.search.tweets(q = q, count = 200)\n",
    "    statuses = search_results['statuses']\n",
    "    max_results = min(1000,max_results)\n",
    "    for _ in range(10):          \n",
    "        try:\n",
    "            next_results = search_results['search_metadata']['next_results']\n",
    "        except KeyError as e: \n",
    "            break\n",
    "        kwargs = dict([ keyvalue.split('=') for keyvalue in next_results[1:].split(\"&\")])\n",
    "        search_results = twitter_api.search.tweets(**kwargs)\n",
    "        statuses += search_results['statuses']\n",
    "        if len(statuses) > max_results:\n",
    "            break\n",
    "    return statuses\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"tweets_data = pd.DataFrame({'favorites_count' : favorites,\\n 'retweet_count' : retweets,\\n 'media_attachment':media\\n  })\\n\""
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = '#JeSuisParis'\n",
    "statuses = twitter_search(twitter.Twitter(auth = auth),q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy ase np\n",
    "import re\n",
    "# Create empty data frame to write with the twitter data\n",
    "df = pd.DataFrame({'status' : statuses})\n",
    "df['favorites'] = np.nan\n",
    "df['retweets'] = np.nan\n",
    "df['media'] = np.nan\n",
    "\n",
    "# For each status in statuses, grab favorites, retweets, and media entities\n",
    "for j in range(len(statuses)):                           \n",
    "    favorite = statuses[j]['favorite_count']\n",
    "    retweet = statuses[j]['retweet_count'] \n",
    "    entities = statuses[j]['entities']\n",
    "    # Match string 'media' to locate media dictionary in each tweet's data\n",
    "    entities = str(entities)\n",
    "    match = re.search(r'media',entities)\n",
    "    # If matched, locate 'type' key and replace media list entry with its associated value and remove extra notation\n",
    "    if match:\n",
    "            entities = entities.split('type')[1]\n",
    "            entities = entities[4:]\n",
    "            entities = entities.replace(\"'\", \"-\")\n",
    "            df.loc[j, 'media'] = entities.split('-')[0]\n",
    "    # rewrite the data frame\n",
    "    df.loc[j, 'favorites'] = favorite\n",
    "    df.loc[j, 'retweets'] = retweet\n",
    "# replace missing values in media column with \"none\" for no media attachment\n",
    "df['media'].fillna('None', inplace=True)\n",
    "\n",
    "# create finished data frame\n",
    "df = df[['favorites','retweets','media']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write to csv- analysis continues in R\n",
    "df.to_csv(\"twitter.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
